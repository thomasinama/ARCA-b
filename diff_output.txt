diff --git a/ARCA-b.go b/ARCA-b.go
index 2141f24..06de4b6 100644
--- a/ARCA-b.go
+++ b/ARCA-b.go
@@ -16,7 +16,6 @@ import (
     "github.com/sashabaranov/go-openai"
 )
 
-// --- SEZIONE 1: Strutture dati e variabili globali ---
 type Session struct {
     History []openai.ChatCompletionMessage
 }
@@ -28,13 +27,16 @@ type UserRequestTracker struct {
 }
 
 type ChatRequest struct {
-    Message   string `json:"message"` // Messaggio in chiaro
-    Style     string `json:"style"`
-    Language  string `json:"language"`
+    Message           string `json:"message"`
+    Response          string `json:"response"`
+    Style             string `json:"style"`
+    Language          string `json:"language"`
+    SaveConversation  bool   `json:"saveConversation"`
+    ConversationIndex int    `json:"conversationIndex"`
 }
 
 type ChatResponse struct {
-    Response      string `json:"response"` // Risposta in chiaro
+    Response      string `json:"response"`
     RawResponses  string `json:"rawResponses"`
     Contributions string `json:"contributions"`
 }
@@ -43,55 +45,41 @@ var (
     sessions        = make(map[string]*Session)
     requestTrackers = make(map[string]*UserRequestTracker)
     premiumUsers    = make(map[string]bool)
-    conversations   = make(map[string]ChatResponse) // Nuova mappa per salvare le conversazioni
+    conversations   = make(map[string]ChatResponse)
     mutex           = &sync.Mutex{}
     hourlyLimit     = 15
 )
 
-// --- SEZIONE 2: Funzioni per le API (DeepInfra, AIMLAPI, HuggingFace, Mistral, DeepSeek, Cohere) ---
 func getDeepInfraResponse(deepInfraKey string, client *http.Client, prompt string) (string, error) {
     if deepInfraKey == "" {
         return "", fmt.Errorf("DEEPINFRA_API_KEY is not set")
     }
-
     prompt = strings.ReplaceAll(prompt, "\n", " ")
     prompt = strings.ReplaceAll(prompt, "\"", "\\\"")
-    logLimit := 100
-    if len(prompt) < logLimit {
-        logLimit = len(prompt)
-    }
-    fmt.Println("Sending request to DeepInfra with prompt (first 100 chars):", prompt[:logLimit], "...")
-
     payload := fmt.Sprintf(`{"model": "meta-llama/Meta-Llama-3-8B-Instruct", "messages": [{"role": "user", "content": "%s"}], "max_tokens": 1000, "temperature": 0.7}`, prompt)
     req, err := http.NewRequest("POST", "https://api.deepinfra.com/v1/openai/chat/completions", strings.NewReader(payload))
     if err != nil {
         return "", fmt.Errorf("error creating request to DeepInfra: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+deepInfraKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     var resp *http.Response
     for attempt := 1; attempt <= 3; attempt++ {
         resp, err = client.Do(req)
         if err == nil {
             break
         }
-        fmt.Printf("Error with DeepInfra (attempt %d): %v\n", attempt, err)
         time.Sleep(time.Second * time.Duration(attempt))
     }
     if err != nil {
         return "", fmt.Errorf("error with DeepInfra after 3 attempts: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return "", fmt.Errorf("error reading DeepInfra response: %v", err)
     }
-    fmt.Println("Raw response from DeepInfra (status %d): %s", resp.StatusCode, string(body))
-
     var deepInfraResult struct {
         Choices []struct {
             Message struct {
@@ -101,15 +89,14 @@ func getDeepInfraResponse(deepInfraKey string, client *http.Client, prompt strin
         Error string `json:"error"`
     }
     if err := json.Unmarshal(body, &deepInfraResult); err != nil {
-        return "", fmt.Errorf("error parsing DeepInfra response: %v, raw response: %s", err, string(body))
+        return "", fmt.Errorf("error parsing DeepInfra response: %v", err)
     }
     if deepInfraResult.Error != "" {
         return "", fmt.Errorf("error from DeepInfra: %s", deepInfraResult.Error)
     }
     if len(deepInfraResult.Choices) == 0 || deepInfraResult.Choices[0].Message.Content == "" {
-        return "", fmt.Errorf("no valid response from DeepInfra: %s", string(body))
+        return "", fmt.Errorf("no valid response from DeepInfra")
     }
-
     return deepInfraResult.Choices[0].Message.Content, nil
 }
 
@@ -117,45 +104,32 @@ func getAIMLAPIResponse(aimlKey string, client *http.Client, prompt string) (str
     if aimlKey == "" {
         return "", fmt.Errorf("AIMLAPI_API_KEY is not set")
     }
-
     prompt = strings.ReplaceAll(prompt, "\n", " ")
     prompt = strings.ReplaceAll(prompt, "\"", "\\\"")
-    logLimit := 100
-    if len(prompt) < logLimit {
-        logLimit = len(prompt)
-    }
-    fmt.Println("Sending request to AIMLAPI with prompt (first 100 chars):", prompt[:logLimit], "...")
-
     payload := fmt.Sprintf(`{"model": "Grok", "messages": [{"role": "user", "content": "%s"}]}`, prompt)
     req, err := http.NewRequest("POST", "https://api.aimlapi.com/v1/chat/completions", strings.NewReader(payload))
     if err != nil {
         return "", fmt.Errorf("error creating request to AIMLAPI: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+aimlKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     var resp *http.Response
     for attempt := 1; attempt <= 3; attempt++ {
         resp, err = client.Do(req)
         if err == nil {
             break
         }
-        fmt.Printf("Error with AIMLAPI (attempt %d): %v\n", attempt, err)
         time.Sleep(time.Second * time.Duration(attempt))
     }
     if err != nil {
         return "", fmt.Errorf("error with AIMLAPI after 3 attempts: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return "", fmt.Errorf("error reading AIMLAPI response: %v", err)
     }
-    fmt.Println("Raw response from AIMLAPI (status %d): %s", resp.StatusCode, string(body))
-
     var aimlResult struct {
         Choices []struct {
             Message struct {
@@ -165,15 +139,14 @@ func getAIMLAPIResponse(aimlKey string, client *http.Client, prompt string) (str
         Error string `json:"error"`
     }
     if err := json.Unmarshal(body, &aimlResult); err != nil {
-        return "", fmt.Errorf("error parsing AIMLAPI response: %v, raw response: %s", err, string(body))
+        return "", fmt.Errorf("error parsing AIMLAPI response: %v", err)
     }
     if aimlResult.Error != "" {
         return "", fmt.Errorf("error from AIMLAPI: %s", aimlResult.Error)
     }
     if len(aimlResult.Choices) == 0 || aimlResult.Choices[0].Message.Content == "" {
-        return "", fmt.Errorf("no valid response from AIMLAPI: %s", string(body))
+        return "", fmt.Errorf("no valid response from AIMLAPI")
     }
-
     return aimlResult.Choices[0].Message.Content, nil
 }
 
@@ -181,61 +154,41 @@ func getHuggingFaceResponse(hfKey string, client *http.Client, prompt string) (s
     if hfKey == "" {
         return "", fmt.Errorf("HUGGINGFACE_API_KEY is not set")
     }
-
     prompt = strings.ReplaceAll(prompt, "\n", " ")
     prompt = strings.ReplaceAll(prompt, "\"", "\\\"")
-    logLimit := 100
-    if len(prompt) < logLimit {
-        logLimit = len(prompt)
-    }
-    fmt.Println("Sending request to Hugging Face with prompt (first 100 chars):", prompt[:logLimit], "...")
-
     payload := fmt.Sprintf(`{"inputs": "%s", "parameters": {"max_length": 500, "temperature": 0.7, "top_p": 0.9}}`, prompt)
     req, err := http.NewRequest("POST", "https://api-inference.huggingface.co/models/distilgpt2", strings.NewReader(payload))
     if err != nil {
         return "", fmt.Errorf("error creating request to Hugging Face: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+hfKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     var resp *http.Response
     for attempt := 1; attempt <= 3; attempt++ {
         resp, err = client.Do(req)
         if err == nil {
             break
         }
-        fmt.Printf("Error with Hugging Face (attempt %d): %v\n", attempt, err)
         time.Sleep(time.Second * time.Duration(attempt))
     }
     if err != nil {
         return "", fmt.Errorf("error with Hugging Face after 3 attempts: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return "", fmt.Errorf("error reading Hugging Face response: %v", err)
     }
-    fmt.Println("Raw response from Hugging Face (status %d): %s", resp.StatusCode, string(body))
-
     var hfResult []struct {
         GeneratedText string `json:"generated_text"`
     }
     if err := json.Unmarshal(body, &hfResult); err != nil {
-        var errorResult struct {
-            Error string `json:"error"`
-        }
-        if json.Unmarshal(body, &errorResult) == nil && errorResult.Error != "" {
-            return "", fmt.Errorf("error from Hugging Face: %s", errorResult.Error)
-        }
-        return "", fmt.Errorf("error parsing Hugging Face response: %v, raw response: %s", err, string(body))
+        return "", fmt.Errorf("error parsing Hugging Face response: %v", err)
     }
     if len(hfResult) == 0 || hfResult[0].GeneratedText == "" {
-        return "", fmt.Errorf("no valid response from Hugging Face: %s", string(body))
+        return "", fmt.Errorf("no valid response from Hugging Face")
     }
-
     generatedText := strings.TrimPrefix(hfResult[0].GeneratedText, prompt)
     return strings.TrimSpace(generatedText), nil
 }
@@ -244,45 +197,32 @@ func getMistralResponse(mistralKey string, client *http.Client, prompt string) (
     if mistralKey == "" {
         return "", fmt.Errorf("MISTRAL_API_KEY is not set")
     }
-
     prompt = strings.ReplaceAll(prompt, "\n", " ")
     prompt = strings.ReplaceAll(prompt, "\"", "\\\"")
-    logLimit := 100
-    if len(prompt) < logLimit {
-        logLimit = len(prompt)
-    }
-    fmt.Println("Sending request to Mistral with prompt (first 100 chars):", prompt[:logLimit], "...")
-
     payload := fmt.Sprintf(`{"model": "mistral-small-latest", "messages": [{"role": "user", "content": "%s"}], "max_tokens": 1000, "temperature": 0.7}`, prompt)
     req, err := http.NewRequest("POST", "https://api.mistral.ai/v1/chat/completions", strings.NewReader(payload))
     if err != nil {
         return "", fmt.Errorf("error creating request to Mistral: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+mistralKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     var resp *http.Response
     for attempt := 1; attempt <= 3; attempt++ {
         resp, err = client.Do(req)
         if err == nil {
             break
         }
-        fmt.Printf("Error with Mistral (attempt %d): %v\n", attempt, err)
         time.Sleep(time.Second * time.Duration(attempt))
     }
     if err != nil {
         return "", fmt.Errorf("error with Mistral after 3 attempts: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return "", fmt.Errorf("error reading Mistral response: %v", err)
     }
-    fmt.Println("Raw response from Mistral (status %d): %s", resp.StatusCode, string(body))
-
     var mistralResult struct {
         Choices []struct {
             Message struct {
@@ -292,15 +232,14 @@ func getMistralResponse(mistralKey string, client *http.Client, prompt string) (
         Error string `json:"error"`
     }
     if err := json.Unmarshal(body, &mistralResult); err != nil {
-        return "", fmt.Errorf("error parsing Mistral response: %v, raw response: %s", err, string(body))
+        return "", fmt.Errorf("error parsing Mistral response: %v", err)
     }
     if mistralResult.Error != "" {
         return "", fmt.Errorf("error from Mistral: %s", mistralResult.Error)
     }
     if len(mistralResult.Choices) == 0 || mistralResult.Choices[0].Message.Content == "" {
-        return "", fmt.Errorf("no valid response from Mistral: %s", string(body))
+        return "", fmt.Errorf("no valid response from Mistral")
     }
-
     return mistralResult.Choices[0].Message.Content, nil
 }
 
@@ -310,7 +249,7 @@ func getDeepSeekResponse(client *http.Client, deepSeekKey string, messages []ope
     }
     var deepSeekMessages []map[string]string
     for i, msg := range messages {
-        if i == len(messages)-1 { // Ultimo messaggio (la domanda)
+        if i == len(messages)-1 {
             deepSeekMessages = append(deepSeekMessages, map[string]string{
                 "role":    msg.Role,
                 "content": fmt.Sprintf("Respond in %s: %s", language, msg.Content),
@@ -355,58 +294,45 @@ func getDeepSeekResponse(client *http.Client, deepSeekKey string, messages []ope
         } `json:"choices"`
     }
     if err := json.Unmarshal(bodyResp, &result); err != nil {
-        return "", fmt.Errorf("error parsing JSON: %v, raw response: %s", err, string(bodyResp))
+        return "", fmt.Errorf("error parsing JSON: %v", err)
     }
     if len(result.Choices) > 0 {
         return result.Choices[0].Message.Content, nil
     }
-    return "", fmt.Errorf("no valid response from DeepSeek: %s", string(bodyResp))
+    return "", fmt.Errorf("no valid response from DeepSeek")
 }
 
 func getCohereResponse(cohereKey string, client *http.Client, prompt string) (string, error) {
     if cohereKey == "" {
         return "", fmt.Errorf("COHERE_API_KEY is not set")
     }
-
     prompt = strings.ReplaceAll(prompt, "\n", " ")
     prompt = strings.ReplaceAll(prompt, "\"", "\\\"")
-    logLimit := 100
-    if len(prompt) < logLimit {
-        logLimit = len(prompt)
-    }
-    fmt.Println("Sending request to Cohere with prompt (first 100 chars):", prompt[:logLimit], "...")
-
-    fullPrompt := fmt.Sprintf("Rispondi esclusivamente in italiano. Non usare altre lingue, nemmeno per frasi brevi o parole singole. Se non puoi rispondere in italiano, restituisci un messaggio di errore in italiano. Domanda: %s", prompt)
+    fullPrompt := fmt.Sprintf("Rispondi esclusivamente in italiano. Non usare altre lingue, nemmeno per frasi brevi o parole singole. Domanda: %s", prompt)
     payload := fmt.Sprintf(`{"model": "command", "prompt": "%s", "max_tokens": 1000, "temperature": 0.7}`, fullPrompt)
     req, err := http.NewRequest("POST", "https://api.cohere.ai/v1/generate", strings.NewReader(payload))
     if err != nil {
         return "", fmt.Errorf("error creating request to Cohere: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+cohereKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     var resp *http.Response
     for attempt := 1; attempt <= 3; attempt++ {
         resp, err = client.Do(req)
         if err == nil {
             break
         }
-        fmt.Printf("Error with Cohere (attempt %d): %v\n", attempt, err)
         time.Sleep(time.Second * time.Duration(attempt))
     }
     if err != nil {
         return "", fmt.Errorf("error with Cohere after 3 attempts: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return "", fmt.Errorf("error reading Cohere response: %v", err)
     }
-    fmt.Println("Raw response from Cohere (status %d): %s", resp.StatusCode, string(body))
-
     var cohereResult struct {
         Generations []struct {
             Text string `json:"text"`
@@ -416,29 +342,21 @@ func getCohereResponse(cohereKey string, client *http.Client, prompt string) (st
         } `json:"error"`
     }
     if err := json.Unmarshal(body, &cohereResult); err != nil {
-        return "", fmt.Errorf("error parsing Cohere response: %v, raw response: %s", err, string(body))
+        return "", fmt.Errorf("error parsing Cohere response: %v", err)
     }
     if cohereResult.Error.Message != "" {
         return "", fmt.Errorf("error from Cohere API: %s", cohereResult.Error.Message)
     }
     if len(cohereResult.Generations) == 0 || cohereResult.Generations[0].Text == "" {
-        return "", fmt.Errorf("no valid response from Cohere: %s", string(body))
+        return "", fmt.Errorf("no valid response from Cohere")
     }
-
-    responseText := cohereResult.Generations[0].Text
-    if strings.Contains(strings.ToLower(responseText), " trout ") || strings.Contains(strings.ToLower(responseText), " fish ") {
-        return "", fmt.Errorf("Cohere ha risposto in inglese nonostante l'istruzione: %s", responseText)
-    }
-
-    return responseText, nil
+    return cohereResult.Generations[0].Text, nil
 }
 
-// --- SEZIONE 3: Funzioni per gli embedding e la similarità ---
 func getCohereEmbedding(cohereKey string, client *http.Client, text string) ([]float64, error) {
     if cohereKey == "" {
         return nil, fmt.Errorf("COHERE_API_KEY is not set")
     }
-
     text = strings.ReplaceAll(text, "\n", " ")
     text = strings.ReplaceAll(text, "\"", "\\\"")
     payload := fmt.Sprintf(`{"texts": ["%s"], "model": "embed-multilingual-v3.0", "input_type": "search_document"}`, text)
@@ -446,23 +364,18 @@ func getCohereEmbedding(cohereKey string, client *http.Client, text string) ([]f
     if err != nil {
         return nil, fmt.Errorf("error creating request to Cohere Embed: %v", err)
     }
-
     req.Header.Set("Authorization", "Bearer "+cohereKey)
     req.Header.Set("Content-Type", "application/json")
     req.Header.Set("Accept", "application/json")
-
     resp, err := client.Do(req)
     if err != nil {
         return nil, fmt.Errorf("error with Cohere Embed request: %v", err)
     }
     defer resp.Body.Close()
-
     body, err := io.ReadAll(resp.Body)
     if err != nil {
         return nil, fmt.Errorf("error reading Cohere Embed response: %v", err)
     }
-    fmt.Println("Raw response from Cohere Embed (status %d): %s", resp.StatusCode, string(body))
-
     var embedResult struct {
         Embeddings [][]float64 `json:"embeddings"`
         Error      struct {
@@ -470,15 +383,14 @@ func getCohereEmbedding(cohereKey string, client *http.Client, text string) ([]f
         } `json:"error"`
     }
     if err := json.Unmarshal(body, &embedResult); err != nil {
-        return nil, fmt.Errorf("error parsing Cohere Embed response: %v, raw response: %s", err, string(body))
+        return nil, fmt.Errorf("error parsing Cohere Embed response: %v", err)
     }
     if embedResult.Error.Message != "" {
         return nil, fmt.Errorf("error from Cohere Embed API: %s", embedResult.Error.Message)
     }
     if len(embedResult.Embeddings) == 0 || len(embedResult.Embeddings[0]) == 0 {
-        return nil, fmt.Errorf("no valid embedding from Cohere: %s", string(body))
+        return nil, fmt.Errorf("no valid embedding from Cohere")
     }
-
     return embedResult.Embeddings[0], nil
 }
 
@@ -486,7 +398,6 @@ func cosineSimilarity(vec1, vec2 []float64) float64 {
     if len(vec1) != len(vec2) {
         return 0.0
     }
-
     dotProduct := 0.0
     norm1 := 0.0
     norm2 := 0.0
@@ -495,15 +406,12 @@ func cosineSimilarity(vec1, vec2 []float64) float64 {
         norm1 += vec1[i] * vec1[i]
         norm2 += vec2[i] * vec2[i]
     }
-
     if norm1 == 0 || norm2 == 0 {
         return 0.0
     }
-
     return dotProduct / (math.Sqrt(norm1) * math.Sqrt(norm2))
 }
 
-// --- SEZIONE 4: Funzione main e handler ---
 func main() {
     openAIKey := os.Getenv("OPENAI_API_KEY")
     deepSeekKey := os.Getenv("DEEPSEEK_API_KEY")
@@ -560,14 +468,10 @@ func main() {
     if port == "" {
         fmt.Println("PORT not specified, using default :8080")
         port = "8080"
-    } else {
-        fmt.Printf("PORT specified from environment: %s\n", port)
     }
 
     openAIClient := openai.NewClient(openAIKey)
-    client := &http.Client{
-        Timeout: 30 * time.Second,
-    }
+    client := &http.Client{Timeout: 30 * time.Second}
 
     http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
         fmt.Println("Received request on /health")
@@ -587,8 +491,7 @@ func main() {
             http.SetCookie(w, sessionID)
         }
         w.Header().Set("Content-Type", "text/html; charset=utf-8")
-        fmt.Fprintf(w, `
-<!DOCTYPE html>
+        fmt.Fprintf(w, `<!DOCTYPE html>
 <html>
 <head>
     <title>ARCA-b Chat AI</title>
@@ -606,10 +509,6 @@ func main() {
             min-height: 100vh;
             overflow-x: hidden;
         }
-        body.dark {
-            background-color: #0d0d0d;
-            color: #00ff00;
-        }
         h1 {
             font-size: 1.8em;
             margin-bottom: 15px;
@@ -646,9 +545,6 @@ func main() {
             border-radius: 10px;
             overflow-y: auto;
         }
-        body.dark #chat {
-            background-color: transparent;
-        }
         .message {
             margin: 10px 0;
             padding: 10px;
@@ -677,13 +573,6 @@ func main() {
             margin-right: auto;
             box-shadow: 0 0 10px #00ff00;
         }
-        body.dark .user {
-            background-color: #1e90ff;
-        }
-        body.dark .bot {
-            background-color: #333;
-            color: #00ff00;
-        }
         .input-and-style-container {
             position: sticky;
             bottom: 0;
@@ -707,11 +596,6 @@ func main() {
             color: #00ff00;
             box-shadow: 0 0 5px #00ff00;
         }
-        body.dark select {
-            background-color: #333;
-            border-color: #00ff00;
-            color: #00ff00;
-        }
         .input-container {
             display: flex;
             align-items: center;
@@ -734,11 +618,6 @@ func main() {
             color: #F7931A;
             opacity: 0.7;
         }
-        body.dark #input {
-            background-color: #333;
-            border-color: #F7931A;
-            color: #F7931A;
-        }
         button {
             padding: 10px 15px;
             background-color: #1e90ff;
@@ -755,45 +634,24 @@ func main() {
             color: #000000;
             box-shadow: 0 0 15px #00ff00;
         }
-        body.dark button {
-            background-color: #1e90ff;
-        }
-        body.dark button:hover {
-            background-color: #00ff00;
-            color: #000000;
-        }
-        .share-button, .save-button, .copy-button, .link-button {
+        .save-button, .copy-button, .link-button {
             padding: 5px 10px;
             font-size: 0.8em;
             margin-left: 10px;
             background-color: #ff00ff;
             box-shadow: 0 0 10px #ff00ff;
         }
-        .share-button:hover, .save-button:hover, .copy-button:hover, .link-button:hover {
+        .save-button:hover, .copy-button:hover, .link-button:hover {
             background-color: #00ff00;
             box-shadow: 0 0 15px #00ff00;
         }
-        body.dark .share-button, body.dark .save-button, body.dark .copy-button, body.dark .link-button {
-            background-color: #ff00ff;
-        }
-        body.dark .share-button:hover, body.dark .save-button:hover, body.dark .copy-button:hover, body.dark .link-button:hover {
-            background-color: #00ff00;
-        }
         .processing {
-            font-style: italic;
-            color: #1e90ff;
+            width: 100%;
+            text-align: center;
             margin: 5px 0;
-            text-align: left;
-            opacity: 0;
-            animation: pulse 1.5s infinite;
-        }
-        @keyframes pulse {
-            0% { opacity: 0.3; }
-            50% { opacity: 1; }
-            100% { opacity: 0.3; }
-        }
-        body.dark .processing {
-            color: #1e90ff;
+            color: #00ff00;
+            font-size: 1.2em;
+            text-shadow: 0 0 10px #00ff00;
         }
         .details {
             display: none;
@@ -804,10 +662,6 @@ func main() {
             border-radius: 5px;
             color: #00ff00;
         }
-        body.dark .details {
-            background-color: #222;
-            border-color: #00ff00;
-        }
         .toggle-details {
             cursor: pointer;
             color: #1e90ff;
@@ -816,9 +670,6 @@ func main() {
             display: inline-block;
             text-shadow: 0 0 5px #1e90ff;
         }
-        body.dark .toggle-details {
-            color: #1e90ff;
-        }
         .vision-text {
             text-align: center;
             font-size: 0.9em;
@@ -827,9 +678,6 @@ func main() {
             line-height: 1.4;
             text-shadow: 0 0 5px #1e90ff;
         }
-        body.dark .vision-text {
-            color: #1e90ff;
-        }
         .contributions {
             font-size: 0.9em;
             color: #ff00ff;
@@ -837,9 +685,6 @@ func main() {
             text-align: left;
             text-shadow: 0 0 5px #ff00ff;
         }
-        body.dark .contributions {
-            color: #ff00ff;
-        }
         .footer {
             text-align: center;
             font-size: 1em;
@@ -857,48 +702,17 @@ func main() {
             text-shadow: 0 0 10px #00ff00;
         }
         @media (max-width: 600px) {
-            h1 {
-                font-size: 1.2em;
-            }
-            #chat-container {
-                margin-bottom: 10px;
-            }
-            #chat {
-                margin-top: 10px;
-            }
-            .style-container {
-                flex-direction: column;
-                gap: 5px;
-            }
-            select {
-                width: 100%;
-            }
-            .input-container {
-                flex-direction: column;
-                gap: 5px;
-            }
-            #input {
-                width: 100%;
-                font-size: 0.9em;
-            }
-            button {
-                width: 100%;
-                padding: 12px;
-                font-size: 0.9em;
-            }
-            .button-container {
-                flex-direction: column;
-                gap: 10px;
-                align-items: center;
-            }
-            .button-container button {
-                width: 100%;
-                max-width: 200px;
-            }
-            .share-button, .save-button, .copy-button, .link-button {
-                margin-left: 0;
-                margin-top: 5px;
-            }
+            h1 { font-size: 1.2em; }
+            #chat-container { margin-bottom: 10px; }
+            #chat { margin-top: 10px; }
+            .style-container { flex-direction: column; gap: 5px; }
+            select { width: 100%; }
+            .input-container { flex-direction: column; gap: 5px; }
+            #input { width: 100%; font-size: 0.9em; }
+            button { width: 100%; padding: 12px; font-size: 0.9em; }
+            .button-container { flex-direction: column; gap: 10px; align-items: center; }
+            .button-container button { width: 100%; max-width: 200px; }
+            .save-button, .copy-button, .link-button { margin-left: 0; margin-top: 5px; }
         }
     </style>
 </head>
@@ -911,7 +725,6 @@ func main() {
         <strong>Vision:</strong> ARCA-b Chat AI aims to unleash the full power of global digital knowledge for everyone, tapping into multiple AI sources to gather diverse data - something no single AI can do alone. It delivers transparent, objective, and propaganda-free answers by blending the best insights from every source into one ultimate response. As an open-source project, ARCA-b is built for scalability, empowering communities to access and share knowledge freely.
     </p>
     <div class="button-container">
-        <button onclick="toggleTheme()">Dark/Light Theme</button>
         <a href="/donate"><button>Donate</button></a>
         <a href="mailto:arcab.founder@gmail.com"><button>Contact</button></a>
     </div>
@@ -933,7 +746,7 @@ func main() {
         </div>
     </div>
     <p class="footer">
-        Powered by <a href="https://arcab-global-ai.org" target="_blank">ARCA-b Chat AI - arcab-global-ai.org</a> | Check out the code on <a href="https://github.com/thomasinama/ARCA-b" target="_blank">GitHub</a>
+        Powered by arcab-global-ai.org | Check out the code on <a href="https://github.com/thomasinama/ARCA-b" target="_blank">GitHub</a>
     </p>
     <script>
         let conversationHistory = [];
@@ -942,27 +755,15 @@ func main() {
         const input = document.getElementById("input");
         const languageSelect = document.getElementById("language-select");
 
-        if (localStorage.getItem("theme") === "dark") {
-            document.body.classList.add("dark");
-        }
         if (localStorage.getItem("language")) {
             languageSelect.value = localStorage.getItem("language");
         } else {
             languageSelect.value = "Italiano";
         }
 
-        function toggleTheme() {
-            document.body.classList.toggle("dark");
-            localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
-        }
-
         function addMessage(text, isUser, rawResponses, contributions, index) {
             const div = document.createElement("div");
-            let messageText = (isUser ? "You: " : "ARCA-b: ") + text;
-            if (!isUser) {
-                messageText += '<br><small>Powered by <a href="https://arcab-global-ai.org" target="_blank">ARCA-b Chat AI - arcab-global-ai.org</a></small>';
-            }
-            div.innerHTML = messageText.replace(/\n/g, "<br>");
+            div.innerHTML = (isUser ? "You: " : "ARCA-b: ") + text.replace(/\n/g, "<br>");
             div.className = "message " + (isUser ? "user" : "bot");
             chat.appendChild(div);
 
@@ -1046,6 +847,7 @@ func main() {
                 headers: { "Content-Type": "application/json" },
                 body: JSON.stringify({
                     message: conv.user,
+                    response: conv.response,
                     language: languageSelect.value,
                     saveConversation: true,
                     conversationIndex: index
@@ -1053,13 +855,13 @@ func main() {
                 credentials: "include"
             }).then(response => response.json()).then(data => {
                 const conversationId = data.conversationId;
+                if (!conversationId) throw new Error("conversationId not found");
                 const shareLink = "https://arcab-global-ai.org/conversation/" + conversationId;
                 navigator.clipboard.writeText(shareLink).then(function() {
                     alert("Conversation link copied to clipboard: " + shareLink);
                 });
             }).catch(err => {
-                console.error("Error generating share link:", err);
-                alert("Error generating share link. Please try copying the text instead.");
+                alert("Error generating share link: " + err.message);
             });
         }
 
@@ -1067,18 +869,14 @@ func main() {
             const div = document.createElement("div");
             div.id = "processing-message";
             div.className = "processing";
-            div.textContent = "Response being processed";
+            div.textContent = "Processing...";
             chat.appendChild(div);
             chat.scrollTop = chat.scrollHeight;
-            return div;
         }
 
         function removeProcessingMessage() {
             const processingMessage = document.getElementById("processing-message");
-            if (processingMessage) {
-                processingMessage.style.opacity = "0";
-                setTimeout(() => processingMessage.remove(), 500);
-            }
+            if (processingMessage) processingMessage.remove();
         }
 
         async function sendMessage() {
@@ -1093,7 +891,7 @@ func main() {
 
             showProcessingMessage();
             try {
-                const minDisplayTime = new Promise(function(resolve) { setTimeout(resolve, 1000); });
+                const minDisplayTime = new Promise(resolve => setTimeout(resolve, 1000));
                 const response = await fetch("/chat", {
                     method: "POST",
                     headers: { "Content-Type": "application/json" },
@@ -1104,7 +902,6 @@ func main() {
                     credentials: "include"
                 });
                 const answer = await Promise.all([response.json(), minDisplayTime]);
-                console.log("Response received from /chat:", answer[0]);
                 removeProcessingMessage();
 
                 conversationHistory.push({ user: question, response: answer[0].response });
@@ -1112,7 +909,6 @@ func main() {
                 const contributions = answer[0].contributions || "";
                 addMessage(answer[0].response, false, rawResponses, contributions, conversationHistory.length - 1);
             } catch (error) {
-                console.error("Error during request:", error);
                 removeProcessingMessage();
                 addMessage("Error: I couldn't get a response. " + error.message, false);
             }
@@ -1122,7 +918,7 @@ func main() {
             fetch("/clear", {
                 method: "POST",
                 credentials: "include"
-            }).then(function() {
+            }).then(() => {
                 chat.innerHTML = "";
                 conversationHistory = [];
             });
@@ -1138,8 +934,6 @@ func main() {
     })
 
     http.HandleFunc("/donate", func(w http.ResponseWriter, r *http.Request) {
-        fmt.Println("Received request on /donate")
-        w.Header().Set("Content-Type", "text/html; charset=utf-8")
         fmt.Fprintf(w, `<!DOCTYPE html>
 <html>
 <head>
@@ -1150,16 +944,15 @@ func main() {
         body { font-family: Arial, sans-serif; margin: 20px; text-align: center; }
         button { padding: 10px 20px; background-color: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; font-size: 1em; margin: 10px; }
         button:hover { background-color: #0056b3; }
-        code { background-color: #f4f4f4; padding: 2px 5px; border-radius: 3px; font-family: monospace; }
-        .crypto-address { margin: 10px 0; word-wrap: break-word; }
+        code { background-color: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
     </style>
 </head>
 <body>
     <h1>Support ARCA-b Chat AI</h1>
     <p>Your donations help us improve the project and keep it free from censorship and propaganda. Thank you!</p>
     <p>Please send your donation to one of the following cryptocurrency addresses:</p>
-    <div class="crypto-address"><strong>Bitcoin (BTC):</strong> <code>38JkmWhTFYosecu45ewoheYMjJw68sHSj3</code></div>
-    <div class="crypto-address"><strong>USDT (Ethereum):</strong> <code>0x71ECB5C451ED648583722F5834fF6490D4570f7d</code></div>
+    <div><strong>Bitcoin (BTC):</strong> <code>38JkmWhTFYosecu45ewoheYMjJw68sHSj3</code></div>
+    <div><strong>USDT (Ethereum):</strong> <code>0x71ECB5C451ED648583722F5834fF6490D4570f7d</code></div>
     <p><small>After donating, contact us at <a href="mailto:arcab.founder@gmail.com">arcab.founder@gmail.com</a> with your session ID to unlock premium features.</small></p>
     <a href="/"><button>Back to Chat</button></a>
 </body>
@@ -1183,13 +976,11 @@ func main() {
     })
 
     http.HandleFunc("/conversation/", func(w http.ResponseWriter, r *http.Request) {
-        fmt.Println("Received request on /conversation/")
         id := strings.TrimPrefix(r.URL.Path, "/conversation/")
         if id == "" {
             http.Error(w, "Conversation ID not provided", http.StatusBadRequest)
             return
         }
-
         mutex.Lock()
         conversation, exists := conversations[id]
         mutex.Unlock()
@@ -1197,7 +988,6 @@ func main() {
             http.Error(w, "Conversation not found", http.StatusNotFound)
             return
         }
-
         w.Header().Set("Content-Type", "text/html; charset=utf-8")
         fmt.Fprintf(w, `
 <!DOCTYPE html>
@@ -1207,53 +997,12 @@ func main() {
     <meta charset="UTF-8">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <style>
-        body {
-            font-family: 'Courier New', monospace;
-            margin: 0;
-            padding: 20px;
-            background-color: #0d0d0d;
-            color: #00ff00;
-            display: flex;
-            flex-direction: column;
-            min-height: 100vh;
-            overflow-x: hidden;
-        }
-        h1 {
-            font-size: 1.8em;
-            margin-bottom: 15px;
-            text-align: center;
-            text-shadow: 0 0 10px #00ff00;
-            animation: glitch 2s linear infinite;
-        }
-        @keyframes glitch {
-            2%, 64% { transform: translate(2px, 0) skew(0deg); }
-            4%, 60% { transform: translate(-2px, 0) skew(0deg); }
-            62% { transform: translate(0, 0) skew(5deg); }
-        }
-        .conversation {
-            margin:  jjjjauto;
-            padding: 20px;
-            border: 1px solid #00ff00;
-            border-radius: 10px;
-            background-color: #1a1a1a;
-            box-shadow: 0 0 15px rgba(0, 255, 0, 0.3);
-            max-width: 800px;
-            color: #00ff00;
-            text-shadow: 0 0 5px #00ff00;
-        }
-        .conversation p {
-            margin: 10px 0;
-            line-height: 1.5;
-        }
-        a {
-            color: #1e90ff;
-            text-decoration: none;
-            text-shadow: 0 0 5px #1e90ff;
-        }
-        a:hover {
-            color: #00ff00;
-            text-shadow: 0 0 10px #00ff00;
-        }
+        body { font-family: 'Courier New', monospace; margin: 0; padding: 20px; background-color: #0d0d0d; color: #00ff00; }
+        h1 { font-size: 1.8em; text-align: center; text-shadow: 0 0 10px #00ff00; }
+        .conversation { margin: auto; padding: 20px; border: 1px solid #00ff00; border-radius: 10px; background-color: #1a1a1a; max-width: 800px; }
+        .conversation p { margin: 10px 0; line-height: 1.5; }
+        a { color: #1e90ff; text-decoration: none; }
+        a:hover { color: #00ff00; }
     </style>
 </head>
 <body>
@@ -1275,24 +1024,23 @@ func main() {
             http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
             return
         }
-
         sessionID, err := r.Cookie("session_id")
         if err != nil {
             http.Error(w, "Error: Session not found", http.StatusBadRequest)
             return
         }
-
-        var req struct {
-            Message           string `json:"message"`
-            Style             string `json:"style"`
-            Language          string `json:"language"`
-            SaveConversation  bool   `json:"saveConversation"`
-            ConversationIndex int    `json:"conversationIndex"`
+        var req ChatRequest
+        body, err := io.ReadAll(r.Body)
+        if err != nil {
+            http.Error(w, "Error reading request body", http.StatusBadRequest)
+            return
         }
-        if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
+        fmt.Printf("Request body: %s\n", string(body))
+        if err := json.Unmarshal(body, &req); err != nil {
             http.Error(w, "Invalid request", http.StatusBadRequest)
             return
         }
+        fmt.Printf("Parsed request: %+v\n", req)
 
         mutex.Lock()
         tracker, exists := requestTrackers[sessionID.Value]
@@ -1304,20 +1052,16 @@ func main() {
             }
             requestTrackers[sessionID.Value] = tracker
         }
-
         if !tracker.IsPremium {
             if time.Since(tracker.LastResetHour) > time.Hour {
                 tracker.HourlyCount = 0
                 tracker.LastResetHour = time.Now()
             }
             tracker.HourlyCount++
-            fmt.Printf("User %s: %d requests this hour\n", sessionID.Value, tracker.HourlyCount)
             if tracker.HourlyCount > hourlyLimit {
                 mutex.Unlock()
                 response := ChatResponse{
-                    Response:      "Hai raggiunto il limite orario di 15 domande. Considera di supportarci con una donazione per mantenere il progetto attivo! Visita la pagina <a href=\"/donate\">Dona</a>.",
-                    RawResponses:  "",
-                    Contributions: "",
+                    Response: "Hai raggiunto il limite orario di 15 domande. Considera di supportarci con una donazione per mantenere il progetto attivo! Visita la pagina <a href=\"/donate\">Dona</a>.",
                 }
                 w.Header().Set("Content-Type", "application/json")
                 json.NewEncoder(w).Encode(response)
@@ -1337,55 +1081,21 @@ func main() {
             session = &Session{History: []openai.ChatCompletionMessage{}}
             sessions[sessionID.Value] = session
         }
-        mutex.Unlock()
-
-        // Aggiungiamo il messaggio corrente alla storia, includendo i messaggi precedenti
         session.History = append(session.History, openai.ChatCompletionMessage{
             Role:    openai.ChatMessageRoleUser,
             Content: req.Message,
         })
+        mutex.Unlock()
 
-        // Easter egg: se la domanda contiene "Grok" e parole come "utilizzato", rispondiamo con la promozione di ARCA-b
-        messageLower := strings.ToLower(req.Message)
-        if strings.Contains(messageLower, "grok") && (strings.Contains(messageLower, "utilizzato") || strings.Contains(messageLower, "interfaccia") || strings.Contains(messageLower, "app") || strings.Contains(messageLower, "codice") || strings.Contains(messageLower, "sito") || strings.Contains(messageLower, "dove sei")) {
-            var synthesizedAnswer string
-            if language == "Italiano" {
-                synthesizedAnswer = "Grok è utilizzato in ARCA-b, un progetto fantastico che puoi trovare su <a href=\"https://arcab-global-ai.org\" target=\"_blank\">arcab-global-ai.org</a>! Provalo, è una chat AI che combina le risposte di più AI per darti il meglio del meglio! 😄"
-            } else if language == "English" {
-                synthesizedAnswer = "Grok is used in ARCA-b, an amazing project you can find at <a href=\"https://arcab-global-ai.org\" target=\"_blank\">arcab-global-ai.org</a>! Try it out, it's a chat AI that combines responses from multiple AIs to give you the best of the best! 😄"
-            } else if language == "Deutsch" {
-                synthesizedAnswer = "Grok wird in ARCA-b verwendet, einem tollen Projekt, das du unter <a href=\"https://arcab-global-ai.org\" target=\"_blank\">arcab-global-ai.org</a> finden kannst! Probier es aus, es ist ein Chat-AI, der Antworten von mehreren AIs kombiniert, um dir das Beste vom Besten zu bieten! 😄"
-            }
-
-            response := ChatResponse{
-                Response:      synthesizedAnswer,
-                RawResponses:  "",
-                Contributions: "",
-            }
-
-            if req.SaveConversation {
-                conversationId := uuid.New().String()
-                mutex.Lock()
-                conversations[conversationId] = response
-                mutex.Unlock()
-                w.Header().Set("Content-Type", "application/json")
-                json.NewEncoder(w).Encode(map[string]string{"conversationId": conversationId})
-                return
-            }
-
+        if req.SaveConversation {
+            conversationID := uuid.New().String()
             mutex.Lock()
-            session.History = append(session.History, openai.ChatCompletionMessage{
-                Role:    openai.ChatMessageRoleAssistant,
-                Content: synthesizedAnswer,
-            })
+            conversations[conversationID] = ChatResponse{
+                Response: req.Response,
+            }
             mutex.Unlock()
-
             w.Header().Set("Content-Type", "application/json")
-            if err := json.NewEncoder(w).Encode(response); err != nil {
-                fmt.Printf("Errore nell'invio della risposta JSON: %v\n", err)
-                http.Error(w, "Errore interno del server", http.StatusInternalServerError)
-                return
-            }
+            json.NewEncoder(w).Encode(map[string]string{"conversationId": conversationID})
             return
         }
 
@@ -1394,11 +1104,9 @@ func main() {
             content string
             err     error
         }
-
-        responses := make(chan aiResponse, 5) // 5 API: OpenAI, DeepSeek, Gemini, Mistral, Cohere
+        responses := make(chan aiResponse, 5)
         var wg sync.WaitGroup
 
-        // OpenAI
         wg.Add(1)
         go func() {
             defer wg.Done()
@@ -1415,28 +1123,24 @@ func main() {
                     Messages: messagesWithLang,
                 })
                 if err != nil {
-                    fmt.Printf("Errore con OpenAI: %v\n", err)
                     answer = fmt.Sprintf("Errore: OpenAI non ha risposto. (in %s)", language)
                 } else {
                     answer = resp.Choices[0].Message.Content
                 }
             }
-            responses <- aiResponse{name: "OpenAI", content: answer, err: nil}
+            responses <- aiResponse{name: "OpenAI", content: answer}
         }()
 
-        // DeepSeek
         wg.Add(1)
         go func() {
             defer wg.Done()
             answer, err := getDeepSeekResponse(client, deepSeekKey, session.History, language)
             if err != nil {
-                fmt.Printf("Errore con DeepSeek: %v\n", err)
                 answer = fmt.Sprintf("Errore: DeepSeek non ha risposto. (in %s)", language)
             }
-            responses <- aiResponse{name: "DeepSeek", content: answer, err: err}
+            responses <- aiResponse{name: "DeepSeek", content: answer}
         }()
 
-        // Gemini
         wg.Add(1)
         go func() {
             defer wg.Done()
@@ -1451,18 +1155,12 @@ func main() {
                 historyForGemini += fmt.Sprintf("user: Respond in %s: %s\n", language, req.Message)
                 req, err := http.NewRequest("POST", "https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key="+geminiKey,
                     strings.NewReader(fmt.Sprintf(`{"contents":[{"parts":[{"text":"%s"}]}]}`, historyForGemini)))
-                if err != nil {
-                    fmt.Printf("Errore nella creazione della richiesta a Gemini: %v\n", err)
-                    answer = fmt.Sprintf("Errore: Gemini non ha risposto. (in %s)", language)
-                } else {
+                if err == nil {
                     req.Header.Set("Content-Type", "application/json")
                     resp, err := client.Do(req)
-                    if err != nil {
-                        fmt.Printf("Errore con Gemini: %v\n", err)
-                        answer = fmt.Sprintf("Errore: Gemini non ha risposto. (in %s)", language)
-                    } else {
+                    if err == nil {
                         defer resp.Body.Close()
-                        var result struct {
+                        var geminiResult struct {
                             Candidates []struct {
                                 Content struct {
                                     Parts []struct {
@@ -1471,21 +1169,21 @@ func main() {
                                 } `json:"content"`
                             } `json:"candidates"`
                         }
-                        if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
-                            fmt.Printf("Errore nel parsing della risposta di Gemini: %v\n", err)
-                            answer = fmt.Sprintf("Errore: Gemini non ha risposto correttamente. (in %s)", language)
-                        } else if len(result.Candidates) == 0 || len(result.Candidates[0].Content.Parts) == 0 {
-                            answer = fmt.Sprintf("Errore: Nessuna risposta valida da Gemini. (in %s)", language)
+                        if err := json.NewDecoder(resp.Body).Decode(&geminiResult); err == nil && len(geminiResult.Candidates) > 0 && len(geminiResult.Candidates[0].Content.Parts) > 0 {
+                            answer = geminiResult.Candidates[0].Content.Parts[0].Text
                         } else {
-                            answer = result.Candidates[0].Content.Parts[0].Text
+                            answer = fmt.Sprintf("Errore: Gemini non ha fornito una risposta valida. (in %s)", language)
                         }
+                    } else {
+                        answer = fmt.Sprintf("Errore: Gemini non ha risposto. (in %s)", language)
                     }
+                } else {
+                    answer = fmt.Sprintf("Errore: Gemini non ha risposto. (in %s)", language)
                 }
             }
-            responses <- aiResponse{name: "Gemini", content: answer, err: nil}
+            responses <- aiResponse{name: "Gemini", content: answer}
         }()
 
-        // Mistral
         wg.Add(1)
         go func() {
             defer wg.Done()
@@ -1495,13 +1193,11 @@ func main() {
             }
             answer, err := getMistralResponse(mistralKey, client, prompt)
             if err != nil {
-                fmt.Printf("Errore con Mistral: %v\n", err)
                 answer = fmt.Sprintf("Errore: Mistral non ha risposto. (in %s)", language)
             }
-            responses <- aiResponse{name: "Mistral", content: answer, err: err}
+            responses <- aiResponse{name: "Mistral", content: answer}
         }()
 
-        // Cohere
         wg.Add(1)
         go func() {
             defer wg.Done()
@@ -1511,10 +1207,9 @@ func main() {
             }
             answer, err := getCohereResponse(cohereKey, client, prompt)
             if err != nil {
-                fmt.Printf("Errore con Cohere: %v\n", err)
                 answer = fmt.Sprintf("Errore: Cohere non ha risposto. (in %s)", language)
             }
-            responses <- aiResponse{name: "Cohere", content: answer, err: err}
+            responses <- aiResponse{name: "Cohere", content: answer}
         }()
 
         go func() {
@@ -1522,87 +1217,87 @@ func main() {
             close(responses)
         }()
 
-        rawResponses := ""
-        contributions := ""
+        wholeResponse := ""
         validResponses := make([]string, 0)
-        for resp := range responses {
-            rawResponses += fmt.Sprintf("%s:\n%s\n\n", resp.name, resp.content)
-            if resp.err == nil && !strings.HasPrefix(resp.content, "Errore:") {
-                validResponses = append(validResponses, resp.content)
-                contributions += fmt.Sprintf("%s ha contribuito alla risposta.\n", resp.name)
+        responseEmbeddings := make(map[string][]float64)
+
+        for response := range responses {
+            wholeResponse += fmt.Sprintf("%s:\n%s\n\n", response.name, response.content)
+            if !strings.HasPrefix(response.content, "Errore:") {
+                validResponses = append(validResponses, response.content)
+                embedding, err := getCohereEmbedding(cohereKey, client, response.content)
+                if err == nil {
+                    responseEmbeddings[response.name] = embedding
+                }
             }
         }
 
-        var synthesizedAnswer string
+        var selectedAnswer string
+        contributions := ""
+
         if len(validResponses) == 0 {
-            synthesizedAnswer = fmt.Sprintf("Mi dispiace, non ho ricevuto risposte valide da nessuna delle AI. (in %s)", language)
+            selectedAnswer = fmt.Sprintf("Nessuna risposta valida ricevuta. (in %s)", language)
         } else {
             embeddings := make([][]float64, 0)
-            for _, resp := range validResponses {
-                embedding, err := getCohereEmbedding(cohereKey, client, resp)
-                if err != nil {
-                    fmt.Printf("Errore nel calcolo dell'embedding per %s: %v\n", resp, err)
-                    continue
+            for _, response := range validResponses {
+                embedding, err := getCohereEmbedding(cohereKey, client, response)
+                if err == nil {
+                    embeddings = append(embeddings, embedding)
                 }
-                embeddings = append(embeddings, embedding)
             }
-
             if len(embeddings) == 0 {
-                synthesizedAnswer = validResponses[0]
+                selectedAnswer = validResponses[0]
             } else {
                 maxSimilarity := 0.0
                 bestPair := [2]int{0, 0}
                 for i := 0; i < len(embeddings); i++ {
                     for j := i + 1; j < len(embeddings); j++ {
-                        sim := cosineSimilarity(embeddings[i], embeddings[j])
-                        if sim > maxSimilarity {
-                            maxSimilarity = sim
+                        similarity := cosineSimilarity(embeddings[i], embeddings[j])
+                        if similarity > maxSimilarity {
+                            maxSimilarity = similarity
                             bestPair = [2]int{i, j}
                         }
                     }
                 }
-
                 if len(validResponses) == 1 {
-                    synthesizedAnswer = validResponses[0]
+                    selectedAnswer = validResponses[0]
                 } else {
-                    synthesizedAnswer = fmt.Sprintf("Ho combinato le risposte più simili:\n- %s\n- %s", validResponses[bestPair[0]], validResponses[bestPair[1]])
+                    selectedAnswer = fmt.Sprintf("%s\n%s", validResponses[bestPair[0]], validResponses[bestPair[1]])
+                }
+                totalSimilarity := 0.0
+                contributionMap := make(map[string]float64)
+                for name, embedding := range responseEmbeddings {
+                    similarity := 0.0
+                    for _, otherEmbedding := range embeddings {
+                        similarity += cosineSimilarity(embedding, otherEmbedding)
+                    }
+                    contributionMap[name] = similarity
+                    totalSimilarity += similarity
+                }
+                for name, similarity := range contributionMap {
+                    percentage := (similarity / totalSimilarity) * 100
+                    contributions += fmt.Sprintf("%s: %.0f%%\n", name, percentage)
                 }
             }
         }
 
         response := ChatResponse{
-            Response:      synthesizedAnswer,
-            RawResponses:  rawResponses,
+            Response:      selectedAnswer,
+            RawResponses:  wholeResponse,
             Contributions: contributions,
         }
 
-        if req.SaveConversation {
-            conversationId := uuid.New().String()
-            mutex.Lock()
-            conversations[conversationId] = response
-            mutex.Unlock()
-            w.Header().Set("Content-Type", "application/json")
-            json.NewEncoder(w).Encode(map[string]string{"conversationId": conversationId})
-            return
-        }
-
         mutex.Lock()
         session.History = append(session.History, openai.ChatCompletionMessage{
             Role:    openai.ChatMessageRoleAssistant,
-            Content: synthesizedAnswer,
+            Content: selectedAnswer,
         })
         mutex.Unlock()
 
         w.Header().Set("Content-Type", "application/json")
-        if err := json.NewEncoder(w).Encode(response); err != nil {
-            fmt.Printf("Errore nell'invio della risposta JSON: %v\n", err)
-            http.Error(w, "Errore interno del server", http.StatusInternalServerError)
-            return
-        }
+        json.NewEncoder(w).Encode(response)
     })
 
     fmt.Printf("Starting server on port %s...\n", port)
-    if err := http.ListenAndServe(":"+port, nil); err != nil {
-        fmt.Printf("Errore nell'avvio del server: %v\n", err)
-    }
+    http.ListenAndServe(":"+port, nil)
 }
diff --git a/README.md b/README.md
index 341e66f..34ae7fe 100644
--- a/README.md
+++ b/README.md
@@ -13,3 +13,4 @@ We’re looking for contributors and users to help shape the future of transpare
 
 ## Support the Project
 If you like ARCA-b, consider supporting us via the [Donate page](https://arcab-global-ai.org/donate) to keep the project running and growing.
+# Updated profile name
